{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgmrMfOArKHq",
        "outputId": "8c7864be-2432-4022-fb6f-69fee6925372"
      },
      "outputs": [],
      "source": [
        "!pip install unidecode\n",
        "!python -m spacy download pt_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRtKlMOurHZd",
        "outputId": "bdb7864d-e792-49d0-8195-458ea5812059"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adagrad\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from unidecode import unidecode\n",
        "import csv\n",
        "from datetime import datetime\n",
        "import os\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "\n",
        "def load_data(filename):\n",
        "    df = pd.read_csv(filename, encoding='utf-8')\n",
        "    df = df[['comentario', 'label_final']]\n",
        "    return df\n",
        "\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "    text = re.sub(r'@\\w+', '', text)\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = unidecode(text)\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    tokens = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('portuguese'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "def get_optimizer(optimizer_name, learning_rate=0.001):\n",
        "    \"\"\"\n",
        "    Retorna o otimizador com base no nome fornecido\n",
        "    \"\"\"\n",
        "    if optimizer_name.lower() == 'adam':\n",
        "        return Adam(learning_rate=learning_rate)\n",
        "    elif optimizer_name.lower() == 'sgd':\n",
        "        return SGD(learning_rate=learning_rate)\n",
        "    elif optimizer_name.lower() == 'rmsprop':\n",
        "        return RMSprop(learning_rate=learning_rate)\n",
        "    elif optimizer_name.lower() == 'adagrad':\n",
        "        return Adagrad(learning_rate=learning_rate)\n",
        "    else:\n",
        "        print(f\"Otimizador {optimizer_name} não reconhecido. Usando Adam como padrão.\")\n",
        "        return Adam(learning_rate=learning_rate)\n",
        "\n",
        "def create_model(max_words, max_len, optimizer_name, loss_function, embedding_dim=100, learning_rate=0.001):\n",
        "    model = Sequential([\n",
        "        Embedding(max_words, 128, input_length=max_len),\n",
        "\n",
        "        \n",
        "        BatchNormalization(),\n",
        "\n",
        "        Bidirectional(LSTM(64, return_sequences=True, kernel_regularizer=l2(0.02))),\n",
        "        Dropout(0.6),  \n",
        "\n",
        "        Bidirectional(LSTM(32, kernel_regularizer=l2(0.02))),\n",
        "        Dropout(0.6),\n",
        "\n",
        "        Dense(64, activation='relu', kernel_regularizer=l2(0.02)),\n",
        "        Dropout(0.6),\n",
        "\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    \n",
        "    optimizer = get_optimizer(optimizer_name, learning_rate)\n",
        "\n",
        "    \n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=loss_function,\n",
        "        metrics=['accuracy', Precision(), Recall()]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "def save_metrics_to_csv(history, metrics, optimizer_name, loss_function, learning_rate, csv_filename='/content/drive/MyDrive/TG/training_metrics2.csv'):\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "    \n",
        "    train_precision = history.history['precision'][-1] if 'precision' in history.history else 0\n",
        "    val_precision = history.history['val_precision'][-1] if 'val_precision' in history.history else 0\n",
        "    train_recall = history.history['recall'][-1] if 'recall' in history.history else 0\n",
        "    val_recall = history.history['val_recall'][-1] if 'val_recall' in history.history else 0\n",
        "\n",
        "    metrics_dict = {\n",
        "        'timestamp': timestamp,\n",
        "        'optimizer': optimizer_name,\n",
        "        'learning_rate': learning_rate,\n",
        "        'loss_function': loss_function,\n",
        "        'train_loss': history.history['loss'][-1],\n",
        "        'val_loss': history.history['val_loss'][-1],\n",
        "        'train_accuracy': history.history['accuracy'][-1],\n",
        "        'val_accuracy': history.history['val_accuracy'][-1],\n",
        "        'train_precision': train_precision,\n",
        "        'val_precision': val_precision,\n",
        "        'train_recall': train_recall,\n",
        "        'val_recall': val_recall,\n",
        "        'test_accuracy': metrics['accuracy'],\n",
        "        'test_precision': metrics['precision'],\n",
        "        'test_recall': metrics['recall'],\n",
        "        'test_f1': metrics['f1_score'],\n",
        "        'best_epoch': metrics['best_epoch'],\n",
        "        'total_epochs': len(history.history['loss'])\n",
        "    }\n",
        "\n",
        "    file_exists = os.path.isfile(csv_filename)\n",
        "\n",
        "    with open(csv_filename, 'a' if file_exists else 'w', newline='') as csvfile:\n",
        "        fieldnames = list(metrics_dict.keys())\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "        if not file_exists:\n",
        "            writer.writeheader()\n",
        "\n",
        "        writer.writerow(metrics_dict)\n",
        "\n",
        "    print(f\"\\nMétricas salvas em {csv_filename}:\")\n",
        "    for key, value in metrics_dict.items():\n",
        "        print(f\"{key}: {value}\")\n",
        "\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred_proba = model.predict(X_test)\n",
        "    y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "\n",
        "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    print(\"\\nMatriz de Confusão:\")\n",
        "    print(f\"Verdadeiros Negativos: {tn}\")\n",
        "    print(f\"Falsos Positivos: {fp}\")\n",
        "    print(f\"Falsos Negativos: {fn}\")\n",
        "    print(f\"Verdadeiros Positivos: {tp}\")\n",
        "\n",
        "    print(f\"\\nMétricas de Avaliação:\")\n",
        "    print(f\"Acurácia: {accuracy:.4f}\")\n",
        "    print(f\"Precisão: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1-Score: {f1_score:.4f}\")\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1_score,\n",
        "        'best_epoch': None\n",
        "    }\n",
        "\n",
        "def run_experiment(X_train, X_test, y_train, y_test, max_words, max_len, optimizer_name, loss_function, learning_rate=0.001):\n",
        "    print(f\"\\nTreinando modelo com optimizer: {optimizer_name} (lr={learning_rate}), loss: {loss_function}\")\n",
        "\n",
        "    model = create_model(max_words, max_len, optimizer_name, loss_function, learning_rate=learning_rate)\n",
        "\n",
        "    \n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=4,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        f'/content/drive/MyDrive/TG/best_model_{optimizer_name}_{loss_function}_lr{learning_rate}_{timestamp}.keras',\n",
        "        monitor='val_accuracy',\n",
        "        save_best_only=True,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        epochs=30,\n",
        "        batch_size=64,\n",
        "        validation_split=0.3,\n",
        "        callbacks=[early_stopping, checkpoint],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    metrics = evaluate_model(model, X_test, y_test)\n",
        "    metrics['best_epoch'] = np.argmax(history.history['val_accuracy']) + 1\n",
        "\n",
        "    save_metrics_to_csv(history, metrics, optimizer_name, loss_function, learning_rate)\n",
        "\n",
        "    return metrics, history, model\n",
        "\n",
        "def save_tokenizer(tokenizer, filename='/content/drive/MyDrive/TG/tokenizer.pickle'):\n",
        "    \"\"\"\n",
        "    Salva o tokenizer em um arquivo pickle\n",
        "    \"\"\"\n",
        "    import pickle\n",
        "    with open(filename, 'wb') as handle:\n",
        "        pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    print(f\"Tokenizer salvo em: {filename}\")\n",
        "\n",
        "def save_best_model(model, optimizer_name, loss_function, learning_rate, metrics, filename=None):\n",
        "    \"\"\"\n",
        "    Salva o melhor modelo treinado\n",
        "    \"\"\"\n",
        "    if filename is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f'/content/drive/MyDrive/TG/best_model_final_{optimizer_name}_{loss_function}_lr{learning_rate}_{timestamp}.keras'\n",
        "\n",
        "    model.save(filename)\n",
        "    print(f\"Melhor modelo salvo em: {filename}\")\n",
        "\n",
        "    \n",
        "    metrics_summary = {\n",
        "        'optimizer': optimizer_name,\n",
        "        'loss_function': loss_function,\n",
        "        'learning_rate': learning_rate,\n",
        "        'accuracy': metrics['accuracy'],\n",
        "        'precision': metrics['precision'],\n",
        "        'recall': metrics['recall'],\n",
        "        'f1_score': metrics['f1_score'],\n",
        "        'best_epoch': metrics['best_epoch']\n",
        "    }\n",
        "\n",
        "    summary_filename = filename.replace('.keras', '_summary.txt')\n",
        "    with open(summary_filename, 'w') as f:\n",
        "        for key, value in metrics_summary.items():\n",
        "            f.write(f\"{key}: {value}\\n\")\n",
        "\n",
        "    print(f\"Resumo das métricas do melhor modelo salvo em: {summary_filename}\")\n",
        "\n",
        "def main():\n",
        "    print(\"Carregando dataset HateBR...\")\n",
        "    \n",
        "    \n",
        "    df = load_data('/content/drive/MyDrive/TG/HateBR.csv')\n",
        "\n",
        "    print(\"Verificando valores únicos em label_final:\")\n",
        "    print(df['label_final'].value_counts())\n",
        "\n",
        "    \n",
        "    df = df.dropna()\n",
        "\n",
        "    print(\"\\nPré-processando textos...\")\n",
        "    df['processed_comment'] = df['comentario'].apply(preprocess_text)\n",
        "\n",
        "    max_words = 15000\n",
        "    max_len = 150\n",
        "\n",
        "    print(\"Tokenizando textos...\")\n",
        "    tokenizer = Tokenizer(num_words=max_words)\n",
        "    tokenizer.fit_on_texts(df['processed_comment'])\n",
        "\n",
        "    \n",
        "    save_tokenizer(tokenizer)\n",
        "\n",
        "    sequences = tokenizer.texts_to_sequences(df['processed_comment'])\n",
        "    X = pad_sequences(sequences, maxlen=max_len)\n",
        "    y = df['label_final'].values\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "    \n",
        "    optimizers = ['adam', 'sgd', 'rmsprop', 'adagrad']\n",
        "    losses = ['binary_crossentropy', 'mean_squared_error', 'hinge', 'categorical_hinge']\n",
        "    learning_rates = [0.001, 0.0005, 0.0001]\n",
        "\n",
        "    \n",
        "    all_results = []\n",
        "    best_metrics = None\n",
        "    best_val_accuracy = 0\n",
        "    best_model = None\n",
        "    best_optimizer = None\n",
        "    best_loss = None\n",
        "    best_lr = None\n",
        "\n",
        "    \n",
        "    for optimizer in optimizers:\n",
        "        for loss in losses:\n",
        "            for lr in learning_rates:\n",
        "                try:\n",
        "                    print(f\"\\n{'='*50}\")\n",
        "                    print(f\"TESTANDO: Optimizer={optimizer}, Loss={loss}, Learning Rate={lr}\")\n",
        "                    print(f\"{'='*50}\")\n",
        "\n",
        "                    metrics, history, model = run_experiment(\n",
        "                        X_train, X_test, y_train, y_test,\n",
        "                        max_words, max_len,\n",
        "                        optimizer, loss, lr\n",
        "                    )\n",
        "\n",
        "                    \n",
        "                    result = {\n",
        "                        'optimizer': optimizer,\n",
        "                        'loss': loss,\n",
        "                        'learning_rate': lr,\n",
        "                        'accuracy': metrics['accuracy'],\n",
        "                        'f1_score': metrics['f1_score'],\n",
        "                        'precision': metrics['precision'],\n",
        "                        'recall': metrics['recall']\n",
        "                    }\n",
        "                    all_results.append(result)\n",
        "\n",
        "                    \n",
        "                    if metrics['f1_score'] > best_val_accuracy:  \n",
        "                        best_val_accuracy = metrics['f1_score']\n",
        "                        best_metrics = metrics\n",
        "                        best_model = model\n",
        "                        best_optimizer = optimizer\n",
        "                        best_loss = loss\n",
        "                        best_lr = lr\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Erro ao treinar com optimizer={optimizer}, loss={loss}, lr={lr}: {str(e)}\")\n",
        "                    continue\n",
        "\n",
        "    \n",
        "    all_results.sort(key=lambda x: x['f1_score'], reverse=True)\n",
        "\n",
        "    \n",
        "    print(\"\\n\\n\" + \"=\"*80)\n",
        "    print(\"RESULTADO DAS EXPERIMENTAÇÕES (ORDENADO POR F1-SCORE)\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"{'Optimizer':<10} | {'Loss':<20} | {'LR':<8} | {'Accuracy':<10} | {'Precision':<10} | {'Recall':<10} | {'F1-Score':<10}\")\n",
        "    print(\"-\"*90)\n",
        "    for result in all_results:\n",
        "        print(f\"{result['optimizer']:<10} | {result['loss']:<20} | {result['learning_rate']:<8.6f} | {result['accuracy']:<10.4f} | {result['precision']:<10.4f} | {result['recall']:<10.4f} | {result['f1_score']:<10.4f}\")\n",
        "\n",
        "    \n",
        "    if best_model is not None:\n",
        "        print(\"\\n\\n\" + \"=\"*50)\n",
        "        print(\"MELHOR CONFIGURAÇÃO ENCONTRADA\")\n",
        "        print(\"=\"*50)\n",
        "        print(f\"Optimizer: {best_optimizer}\")\n",
        "        print(f\"Loss Function: {best_loss}\")\n",
        "        print(f\"Learning Rate: {best_lr}\")\n",
        "        print(f\"Test Accuracy: {best_metrics['accuracy']:.4f}\")\n",
        "        print(f\"Precision: {best_metrics['precision']:.4f}\")\n",
        "        print(f\"Recall: {best_metrics['recall']:.4f}\")\n",
        "        print(f\"F1-Score: {best_metrics['f1_score']:.4f}\")\n",
        "\n",
        "        save_best_model(best_model, best_optimizer, best_loss, best_lr, best_metrics)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Iniciando o programa...\")\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
